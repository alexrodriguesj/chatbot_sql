{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52fb11f4-d28f-4e64-ba4e-801fdcd28068",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fe1c8a-86ed-4ce3-b7b6-ccc8011d1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36940da-135e-4940-b50a-7eeb710238ef",
   "metadata": {},
   "source": [
    "# Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587ff563-a204-47cb-b543-5e0d6e8b7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc17c9-f8be-4dcf-8fc4-5e0127aa2aca",
   "metadata": {},
   "source": [
    "# Connect to SQLite database\n",
    "Creates a connection to the Chinook.db SQLite database using the Langchain SQLDatabase utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e0e92f-6b72-4e0b-b55e-4953ee50037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c7e17a-616e-4604-99f1-184f089eae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    temperature=0.0,\n",
    "    openai_api_key=openai_api_key,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dd5d3f-b6a6-4818-ae97-72d596f9bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ea71d6-61ed-42c0-8dd2-741285ab3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85109b94-7bf2-438b-81e0-f0c71a518d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_api_key = os.getenv('SERPAPI_API_KEY')\n",
    "search = SerpAPIWrapper(serpapi_api_key=serpapi_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77be02ea-faad-4c01-b9a8-46f190c0aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"FooBar-DB\",\n",
    "        func=db_chain.run,\n",
    "        description=\"useful for when you need to answer questions about FooBar. Input should be in the form of a question containing full context\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcca4749-6434-4b10-a6ee-176c738836fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"memory\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7868788c-1b23-4094-9e30-68a6777fe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_kwargs = {\n",
    "    \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"memory\")],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73366bdc-d30b-4a4e-9181-67c75a6f866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\myenv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    agent_kwargs=agent_kwargs,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa245367-3aac-4be3-813e-341d4717dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the handle_chat function\n",
    "def handle_chat(query):\n",
    "    response = agent.invoke({\"input\": query})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47935d35-b048-47f5-bb1d-ed2cefa1c8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FooBar-DB` with `How many artists are there in our database?`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many artists are there in our database?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(*) FROM Artist\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(275,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThere are 275 artists in our database.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3mThere are 275 artists in our database.\u001b[0m\u001b[32;1m\u001b[1;3mThere are 275 artists in our database.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How many artists are there in our database?', 'memory': [HumanMessage(content='How many artists are there in our database?'), AIMessage(content='There are 275 artists in our database.')], 'output': 'There are 275 artists in our database.'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage 01\n",
    "query = \"How many artists are there in our database?\"\n",
    "response = handle_chat(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b585dc-b457-4aaa-a6c0-7164721937da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIf 10 artists died, the total number of artists in our database would be 265.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'If 10 artists died, how many artists are there in our database?', 'memory': [HumanMessage(content='How many artists are there in our database?'), AIMessage(content='There are 275 artists in our database.'), HumanMessage(content='If 10 artists died, how many artists are there in our database?'), AIMessage(content='If 10 artists died, the total number of artists in our database would be 265.')], 'output': 'If 10 artists died, the total number of artists in our database would be 265.'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage 02\n",
    "query = \"If 10 artists died, how many artists are there in our database?\"\n",
    "response = handle_chat(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3fa9669-b7be-4606-b324-f2e2f2a9ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `{'query': 'population size of the capital of France'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mWith an official estimated population of 2,102,650 residents as of 1 January 2023 in an area of more than 105 km2 (41 sq mi), Paris is the fourth-largest city in the European Union and the 30th most densely populated city in the world in 2022.\u001b[0m\u001b[32;1m\u001b[1;3mThe population size of the capital of France, Paris, is estimated to be around 2,102,650 residents as of January 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the population size of the capital of France?', 'memory': [HumanMessage(content='How many artists are there in our database?'), AIMessage(content='There are 275 artists in our database.'), HumanMessage(content='If 10 artists died, how many artists are there in our database?'), AIMessage(content='If 10 artists died, the total number of artists in our database would be 265.'), HumanMessage(content='What is the population size of the capital of France?'), AIMessage(content='The population size of the capital of France, Paris, is estimated to be around 2,102,650 residents as of January 2023.')], 'output': 'The population size of the capital of France, Paris, is estimated to be around 2,102,650 residents as of January 2023.'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage 03\n",
    "query = \"What is the population size of the capital of France?\"\n",
    "response = handle_chat(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
